(window.webpackJsonp=window.webpackJsonp||[]).push([[13],{1184:function(v,_,a){"use strict";a.r(_);var e=a(13),t=Object(e.a)({},(function(){var v=this,_=v.$createElement,e=v._self._c||_;return e("ContentSlotsDistributor",{attrs:{"slot-key":v.$parent.slotKey}},[e("h2",{attrs:{id:"_5-1-引例"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_5-1-引例"}},[v._v("#")]),v._v(" 5.1 引例")]),v._v(" "),e("h3",{attrs:{id:"_5-1-1-问题与传统解决方案"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_5-1-1-问题与传统解决方案"}},[v._v("#")]),v._v(" 5.1.1  问题与传统解决方案")]),v._v(" "),e("p",[v._v("【例5-1】假设现有一些配置完全相同的机器cSlave0~cSlaveN，cMaster0，cMaster1，并且每台机器都有1个双核CPU，5GB硬盘。现有两个大小都是2GB的文件file0和file1。")]),v._v(" "),e("h3",{attrs:{id:"第一类问题-存储。"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#第一类问题-存储。"}},[v._v("#")]),v._v(" 第一类问题，存储。")]),v._v(" "),e("p",[v._v("问题①：将file0和file1存入两台不同机器，但要求对外显示它们存于同一硬盘空间。")]),v._v(" "),e("ul",[e("li",[v._v("取两台机器cSlave0和cSlave1，cSlave0存储file0，cSlave1存储file1。")])]),v._v(" "),e("p",[v._v("问题②：不考虑①，现有一新文件file2，大小为6GB，要求存入机器后对外显示依旧为一个完整文件。")]),v._v(" "),e("ul",[e("li",[v._v("将file2拆成两个大小分别为3GB的文件file2-a和file2-b，将file2-a存入cSlave0、file2-b存入cSlave1。")])]),v._v(" "),e("h3",{attrs:{id:"第二类问题-计算。"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#第二类问题-计算。"}},[v._v("#")]),v._v(" 第二类问题，计算。")]),v._v(" "),e("p",[v._v("问题③：在问题①下，统计file0和file1这两个文件里每个单词出现的次数。")]),v._v(" "),e("ul",[e("li",[v._v("步骤一，将cSlave1上的file1复制一份到cSlave0上，这样cSlave0上同时存有file0和file1。")]),v._v(" "),e("li",[v._v("步骤二，编写一简单程序，程序里使用HashMap<String, Integer>，顺序读取文件，判断新读取的单词是否存在于HashMap，存在Integer+1，不存在则HashMap里加入这个新单词，Integer置为1，记此程序为WordCount。")]),v._v(" "),e("li",[v._v("步骤三，将此程序WordCount放在cSlave0上执行，得出结果。")])]),v._v(" "),e("h3",{attrs:{id:"第三类问题-可靠性。"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#第三类问题-可靠性。"}},[v._v("#")]),v._v(" 第三类问题，可靠性。")]),v._v(" "),e("p",[v._v("问题④：假设用于解决上述问题的机器宕机了，问如何保证数据不丢失。")]),v._v(" "),e("ul",[e("li",[v._v("为每台机器都做磁盘冗余阵列（RAID），购买更稳定的硬件，配置最好的机房、最稳定的网络。")])]),v._v(" "),e("h3",{attrs:{id:"_5-1-3-分布式下的解决方案"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_5-1-3-分布式下的解决方案"}},[v._v("#")]),v._v(" 5.1.3  分布式下的解决方案")]),v._v(" "),e("h4",{attrs:{id:"分布式存储"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#分布式存储"}},[v._v("#")]),v._v(" 分布式存储")]),v._v(" "),e("p",[v._v("对于第一类存储问题，若能将多台机器硬盘以某种方式连接到一起，则问题迎刃而解。取机器cSlave0，cSlave1和cMaster0，采用客户-服务器模式构建分布式存储集群，让cMaster0管理cSlave0，cSlave1。")]),v._v(" "),e("p",[v._v("上层主机只管理，下层主机只存储")]),v._v(" "),e("p",[e("img",{attrs:{src:a(794),alt:"image-20220323103712069"}})]),v._v(" "),e("p",[v._v("在此设计环境下：")]),v._v(" "),e("ul",[e("li",[e("h5",{attrs:{id:"对内"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#对内"}},[v._v("#")]),v._v(" 对内")])])]),v._v(" "),e("p",[v._v("客户-服务器模式：只要保证store master正常工作，我们很容易随意添加store slave，硬盘存储空间无限大。")]),v._v(" "),e("ul",[e("li",[e("h5",{attrs:{id:"对外"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#对外"}},[v._v("#")]),v._v(" 对外")])])]),v._v(" "),e("p",[v._v("统一存储空间，统一文件接口：整个集群就像是一台机器、一片云，硬盘显示为统一存储空间，文件接口统一。")]),v._v(" "),e("p",[e("strong",[v._v("分布式文件系统(Distributed File System，DFS)  ≈  Hadoop分布式文件系统 (Hadoop DFS，HDFS)")])]),v._v(" "),e("h4",{attrs:{id:"分布式计算"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#分布式计算"}},[v._v("#")]),v._v(" 分布式计算")]),v._v(" "),e("p",[e("img",{attrs:{src:a(795),alt:"image-20220323104627420"}})]),v._v(" "),e("p",[e("strong",[v._v("步骤")])]),v._v(" "),e("ul",[e("li",[v._v("本地计算（Map）")]),v._v(" "),e("li",[v._v("洗牌（Shuffle）\n"),e("ul",[e("li",[v._v("规定将Key值相同的KV对，通过网络发往同一台机器。")])])]),v._v(" "),e("li",[v._v("合并再计算（Reduce）")])]),v._v(" "),e("p",[v._v("取新机器cMaster1，采用客户-服务器模式构建由机器cSlave0、cSlave1和cMaster1组成的分布式计算集群。")]),v._v(" "),e("p",[e("img",{attrs:{src:a(796),alt:"image-20220323104856025"}})]),v._v(" "),e("p",[v._v("cSlave0最好是处理存于本机硬盘上的file0，而不是将file1从cSlave1调过来（通过网络）再处理file1，这就是所谓的“本地计算”。")]),v._v(" "),e("p",[e("img",{attrs:{src:a(797),alt:"image-20220323104825938"}})]),v._v(" "),e("p",[e("strong",[v._v("合并 (洗牌)")])]),v._v(" "),e("ul",[e("li",[v._v("第一步：每台机器将各自KV对中的Value连接成一个链表")]),v._v(" "),e("li",[v._v("第二步：各台机器可对<Key,ValueList>进行业务处理，称此过程为Reduce。")]),v._v(" "),e("li",[v._v("第三步：将得出的结果再存于DFS。")])]),v._v(" "),e("p",[v._v("容易看出，无论是Map、Shuffle还是Reduce，甚至是存储结果，在每个阶段都是并行的，整个过程则构成一个有向无环图（DAG）")]),v._v(" "),e("p",[e("img",{attrs:{src:a(798),alt:"image-20220323105729108"}})]),v._v(" "),e("p",[e("strong",[v._v("冗余存储与冗余计算")])]),v._v(" "),e("p",[v._v("只要保证存于cSlave0上的数据，同时还存在于别的机器上，即使cSlave0宕机，数据依旧不会丢失。")]),v._v(" "),e("ul",[e("li",[v._v("存储时\n"),e("ul",[e("li",[v._v("引入新机器cSlave2和cSlave3，将存于cSlave0的file0同样存储于cSlave2，存于cSlave1的file1同样存一份于cSlave3。")])])]),v._v(" "),e("li",[v._v("计算时\n"),e("ul",[e("li",[v._v("cSlave0~3的计算任务统一由cMaster1指派。")]),v._v(" "),e("li",[v._v("cMaster1选中先结束的那台机器的计算结果，并停止另一台机器里还在计算的进程")])])]),v._v(" "),e("li",[v._v("作用\n"),e("ul",[e("li",[v._v("通过冗余存储，不仅提高了分布式存储可靠性，还提高了分布式计算的可靠性。")])])])]),v._v(" "),e("h3",{attrs:{id:"_5-1-4-小结"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_5-1-4-小结"}},[v._v("#")]),v._v(" 5.1.4  小结")]),v._v(" "),e("ul",[e("li",[v._v("现实中Hadoop的实现机制则更加复杂，但其架构的基本思路和本节很类似。")]),v._v(" "),e("li",[v._v("分布式存储和分布式计算这两者间并没有关系，它们各自都可以独立存在。")]),v._v(" "),e("li",[v._v("当MapReduce运行于HDFS上时，性能较好。")])]),v._v(" "),e("h2",{attrs:{id:"_5-2-hadoop-2-0简述"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_5-2-hadoop-2-0简述"}},[v._v("#")]),v._v(" 5.2 Hadoop 2.0简述")]),v._v(" "),e("p",[e("img",{attrs:{src:a(799),alt:"image-20220323110422292"}})]),v._v(" "),e("ul",[e("li",[v._v("将Hadoop 2.0部署至集群后，通过调用Hadoop 2.0程序库，能够用简单的编程模型来处理分布在不同机器上的大规模数据集。")]),v._v(" "),e("li",[v._v("由于采用客户-服务器模式，Hadoop 2.0很容易从一台机器扩展至成千上万台机器，并且每台机器都能提供本地计算存储和本地计算。")]),v._v(" "),e("li",[v._v("考虑到集群中每台机器都可能会出问题（如硬件失效），Hadoop 2.0本身从设计上就在程序层规避了这些问题。")])]),v._v(" "),e("p",[e("strong",[v._v("各个产品项目之间的层次关系")])]),v._v(" "),e("p",[e("img",{attrs:{src:a(800),alt:"image-20220323111007431"}})]),v._v(" "),e("p",[e("strong",[v._v("应用场景")])]),v._v(" "),e("ul",[e("li",[e("p",[v._v("构建大型分布式集群")])]),v._v(" "),e("li",[e("p",[v._v("数据仓库")])]),v._v(" "),e("li",[e("p",[v._v("数据挖掘")])])]),v._v(" "),e("p",[e("strong",[v._v("Google云计算组件和Hadoop及其相关项目之间的对应关系：")])]),v._v(" "),e("table",[e("thead",[e("tr",[e("th",[e("strong",[v._v("Hadoop云计算系统")])]),v._v(" "),e("th",[e("strong",[v._v("Google云计算系统")])])])]),v._v(" "),e("tbody",[e("tr",[e("td",[v._v("Hadoop  HDFS")]),v._v(" "),e("td",[v._v("Google  GFS")])]),v._v(" "),e("tr",[e("td",[v._v("Hadoop  MapReduce")]),v._v(" "),e("td",[v._v("Google  MapReduce")])]),v._v(" "),e("tr",[e("td",[v._v("HBase")]),v._v(" "),e("td",[v._v("Google  BigTable")])]),v._v(" "),e("tr",[e("td",[v._v("ZooKeeper")]),v._v(" "),e("td",[v._v("Google  Chubby")])]),v._v(" "),e("tr",[e("td",[v._v("Pig")]),v._v(" "),e("td",[v._v("Google  Sawzall")])])])]),v._v(" "),e("h2",{attrs:{id:"_5-3-hadoop-2-0部署"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_5-3-hadoop-2-0部署"}},[v._v("#")]),v._v(" 5.3 Hadoop 2.0部署")]),v._v(" "),e("h3",{attrs:{id:"_5-3-1-部署综述"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_5-3-1-部署综述"}},[v._v("#")]),v._v(" 5.3.1  部署综述")]),v._v(" "),e("p",[e("strong",[v._v("制定部署规划")])]),v._v(" "),e("ul",[e("li",[v._v("准备机器")]),v._v(" "),e("li",[v._v("准备机器软件环境")]),v._v(" "),e("li",[v._v("下载Hadoop")]),v._v(" "),e("li",[v._v("解压Hadoop")]),v._v(" "),e("li",[v._v("配置Hadoop")]),v._v(" "),e("li",[v._v("启动Hadoop")]),v._v(" "),e("li",[v._v("测试Hadoop")])]),v._v(" "),e("p",[e("strong",[v._v("硬件环境")]),v._v("\n由于分布式计算需要用到很多机器，部署时用户须提供多台机器，至于提供几台，须根据 “部署规划”确定。\n实际上，完全模式部署Hadoop时，最低需要两台机器（一个主节点，一个从节点），此外，硬件方面，每台机器最低要求有1GB内存，20GB硬盘空间。")]),v._v(" "),e("p",[e("strong",[v._v("软件环境")])]),v._v(" "),e("p",[v._v("大量的实践证明，在Linux环境下使用Hadoop则更加稳定高效\n须注意的是新装系统（CentOS）的机器不可以直接部署Hadoop")]),v._v(" "),e("ul",[e("li",[v._v("修改机器名")]),v._v(" "),e("li",[v._v("添加域名映射")]),v._v(" "),e("li",[v._v("关闭防火墙")]),v._v(" "),e("li",[v._v("安装JDK")])]),v._v(" "),e("p",[e("strong",[v._v("关于Hadoop依赖软件")])]),v._v(" "),e("ul",[e("li",[v._v("SSH只是给sbin/start-yarn.sh等几个start-x.sh与stop-x.sh脚本使用")]),v._v(" "),e("li",[v._v("Hadoop本身是一堆Java代码，而Java代码并不依赖SSH")]),v._v(" "),e("li",[v._v("本节使用的Hadoop版本为稳定版Hadoop-2.2.0.tar.gz")]),v._v(" "),e("li",[v._v("CentOS版本为64位CentOS-6.5")]),v._v(" "),e("li",[v._v("JDK版本为jdk-7u40-linux-x64.rpm")])]),v._v(" "),e("h3",{attrs:{id:"_5-3-2-传统解压包部署"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_5-3-2-传统解压包部署"}},[v._v("#")]),v._v(" 5.3.2  传统解压包部署")]),v._v(" "),e("p",[v._v("现有三台机器，且它们都刚装好64位CentOS-6.5，安装系统时用户名为joe，请按要求完成：")]),v._v(" "),e("ul",[e("li",[e("p",[v._v("修改三台机器名为cMaster，cSlave0和cSlave1，并添加域名映射、关闭防火墙和安装JDK。")])]),v._v(" "),e("li",[e("p",[v._v("以cMaster作为主节点，cSlave0和cSlave1作为从节点，部署Hadoop。")])]),v._v(" "),e("li",[e("p",[v._v("制定部署规划")]),v._v(" "),e("ul",[e("li",[v._v("此Hadoop集群需三台机器（cMaster，cSlave0和cSlave1），其中cMaster作为主节点，cSlave0和cSlave1作为从节点。")])])]),v._v(" "),e("li",[e("p",[v._v("准备机器")]),v._v(" "),e("ul",[e("li",[v._v("准备三台机器，它们可以是实体机也可以是虚拟机，若使用虚拟机。")])])]),v._v(" "),e("li",[e("p",[v._v("准备机器软件环境")]),v._v(" "),e("ul",[e("li",[v._v("三台机器都要完成：修改机器名、添加域名映射、关闭防火墙和安装JDK。")])])]),v._v(" "),e("li",[e("p",[v._v("下载Hadoop")]),v._v(" "),e("ul",[e("li",[v._v("谷歌搜索“Hadoop download”并下载，以joe用户身份，将Hadoop分别复制到三台机器上。")])])]),v._v(" "),e("li",[e("p",[v._v("解压Hadoop")]),v._v(" "),e("ul",[e("li",[v._v("分别以joe用户登录三台机器，每台都执行如下命令解压Hadoop文件：")])])]),v._v(" "),e("li",[e("p",[v._v("配置Hadoop")]),v._v(" "),e("ul",[e("li",[v._v("三台机器都要配置，且配置相同")])])]),v._v(" "),e("li",[e("p",[v._v("启动Hadoop")]),v._v(" "),e("ul",[e("li",[v._v("首先，在主节点cMaster上格式化主节点命名空间")]),v._v(" "),e("li",[v._v("其次，在主节点cMaster上启动存储主服务namenode和资源管理主服务resourcemanager。")]),v._v(" "),e("li",[v._v("最后，在从节点上启动存储从服务datanode和资源管理从服务nodemanager")])])]),v._v(" "),e("li",[e("p",[v._v("测试Hadoop")])])]),v._v(" "),e("h2",{attrs:{id:"_5-4-hadoop-2-0体系架构"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_5-4-hadoop-2-0体系架构"}},[v._v("#")]),v._v(" 5.4 Hadoop 2.0体系架构")]),v._v(" "),e("h3",{attrs:{id:"_5-4-1-hadoop-2-0公共组件common"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_5-4-1-hadoop-2-0公共组件common"}},[v._v("#")]),v._v(" 5.4.1  Hadoop 2.0公共组件Common")]),v._v(" "),e("h3",{attrs:{id:"_5-4-2-分布式文件系统hdfs"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_5-4-2-分布式文件系统hdfs"}},[v._v("#")]),v._v(" 5.4.2  分布式文件系统HDFS")]),v._v(" "),e("p",[e("strong",[v._v("HDFS定位")])]),v._v(" "),e("p",[v._v("为提高扩展性，HDFS采用了master/slave架构来构建分布式存储集群，这种架构很容易向集群中任意添加或删除slave。")]),v._v(" "),e("p",[e("img",{attrs:{src:a(801),alt:"image-20220404090024554"}})]),v._v(" "),e("p",[e("strong",[v._v("HDFS体系架构")])]),v._v(" "),e("p",[v._v("HDFS架构：")]),v._v(" "),e("ul",[e("li",[v._v("HDFS采用master/slave体系来构建分布式存储服务\n"),e("ul",[e("li",[v._v("提高了HDFS的可扩展性又简化了架构设计")])])]),v._v(" "),e("li",[v._v("HDFS里将文件分块存储\n"),e("ul",[e("li",[v._v("优化存储颗粒度")])])]),v._v(" "),e("li",[v._v("namenode统一管理所有slave机器datanode存储空间，datanode以块为单位存储实际的数据")]),v._v(" "),e("li",[v._v("真正的文件I/O操作时客户端直接和datanode交互")])]),v._v(" "),e("p",[v._v("NameNode（主控制服务器）")]),v._v(" "),e("ul",[e("li",[v._v("负责维护文件系统的命名空间（Namespace）")]),v._v(" "),e("li",[v._v("协调客户端对文件的访问")]),v._v(" "),e("li",[v._v("记录命名空间内的任何改动或命名空间本身的属性改动")])]),v._v(" "),e("p",[v._v("DataNode")]),v._v(" "),e("ul",[e("li",[v._v("负责它们所在的物理节点上的存储管理")]),v._v(" "),e("li",[v._v("HDFS开放文件系统的命名空间")])]),v._v(" "),e("p",[v._v("NameNode")]),v._v(" "),e("ul",[e("li",[v._v("执行文件系统的命名空间操作")]),v._v(" "),e("li",[v._v("决定数据块到DataNode的映射")])]),v._v(" "),e("p",[e("img",{attrs:{src:a(802),alt:"image-20220404090545677"}})]),v._v(" "),e("p",[v._v("客户端要访问一个文件")]),v._v(" "),e("ul",[e("li",[v._v("客户端从NameNode获得组成文件的数据块的位置列表")]),v._v(" "),e("li",[v._v("客户端直接从DataNode上读取文件数据")])]),v._v(" "),e("p",[e("strong",[v._v("一般拓扑")])]),v._v(" "),e("ul",[e("li",[v._v("只有单个NameNode节点，")]),v._v(" "),e("li",[v._v("使用SecondaryNameNode或BackupNode节点实时获取NameNode元数据信息，备份元数据。")])]),v._v(" "),e("p",[e("img",{attrs:{src:a(803),alt:"image-20220404091123149"}})]),v._v(" "),e("p",[e("strong",[v._v("商用拓扑")])]),v._v(" "),e("ul",[e("li",[v._v("有两个NameNode节点，")]),v._v(" "),e("li",[v._v("并使用ZooKeeper实现NameNode节点间的热切换。")])]),v._v(" "),e("p",[v._v("ZooKeeper集群：至少三个ZooKeeper实体，用来选举ActiveNamenode。\nJourNalNode集群：至少三个，用于与两NameNode交换数据，也可使用NFS。\nHTTPFS：提供Web端读写HDFS功能。")]),v._v(" "),e("p",[e("strong",[v._v("HDFS内部特性")])]),v._v(" "),e("ul",[e("li",[v._v("冗余备份")]),v._v(" "),e("li",[v._v("副本存放")]),v._v(" "),e("li",[v._v("副本选择")]),v._v(" "),e("li",[v._v("心跳检测")]),v._v(" "),e("li",[v._v("数据完整性检测")]),v._v(" "),e("li",[v._v("元数据磁盘失效")]),v._v(" "),e("li",[v._v("简单一致性模型、流式数据访问")]),v._v(" "),e("li",[v._v("客户端缓存")]),v._v(" "),e("li",[v._v("流水线复制")]),v._v(" "),e("li",[v._v("架构特征")]),v._v(" "),e("li",[v._v("超大规模数据集")])]),v._v(" "),e("p",[e("strong",[v._v("HDFS对外功能")])]),v._v(" "),e("ul",[e("li",[e("p",[v._v("NameNode高可靠性")])]),v._v(" "),e("li",[e("p",[v._v("HDFS快照")])]),v._v(" "),e("li",[e("p",[v._v("元数据管理与恢复工具")])]),v._v(" "),e("li",[e("p",[v._v("HDFS安全性")])]),v._v(" "),e("li",[e("p",[v._v("HDFS配额功能")])]),v._v(" "),e("li",[e("p",[v._v("HDFS C语言接口")])]),v._v(" "),e("li",[e("p",[v._v("HDFS Short-Circuit功能")])]),v._v(" "),e("li",[e("p",[v._v("WebHdfs")])])]),v._v(" "),e("h3",{attrs:{id:"_5-4-3-分布式操作系统yarn"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_5-4-3-分布式操作系统yarn"}},[v._v("#")]),v._v(" 5.4.3  分布式操作系统Yarn")]),v._v(" "),e("p",[e("strong",[v._v("分布式操作系统的基本功能")])]),v._v(" "),e("ul",[e("li",[e("p",[v._v("管理计算机资源")])]),v._v(" "),e("li",[e("p",[v._v("提供用户接口")])])]),v._v(" "),e("p",[e("strong",[v._v("Yarn")])]),v._v(" "),e("ul",[e("li",[v._v("一方面管理整个集群的计算资源（CPU、内存等）")]),v._v(" "),e("li",[v._v("另一方面提供用户程序访问系统资源的API。")])]),v._v(" "),e("p",[e("strong",[v._v("体系架构")])]),v._v(" "),e("p",[v._v("Yarn的主要思想是将MRv1版JobTracker的两大功能——资源管理和任务调度，拆分成两个独立的进程：")]),v._v(" "),e("ul",[e("li",[v._v("资源管理模块\n"),e("ul",[e("li",[v._v("全局资源管理进程ResourceManager")])])]),v._v(" "),e("li",[v._v("任务管理模块\n"),e("ul",[e("li",[v._v("任务管理进程ApplicationMaster")])])])]),v._v(" "),e("p",[v._v("Yarn依旧是master/slave结构")]),v._v(" "),e("p",[v._v("主进程ResourceManager是整个集群资源仲裁中心")]),v._v(" "),e("p",[v._v("从进程NodeManager管理本机资源")]),v._v(" "),e("p",[v._v("ResourceManager和从属节点的进程NodeManager组成了Hadoop 2.0的分布式数据计算框架")]),v._v(" "),e("p",[e("img",{attrs:{src:a(804),alt:"image-20220404102327980"}})]),v._v(" "),e("p",[v._v("Yarn在执行时包含以下独立实体：")]),v._v(" "),e("p",[v._v("① Client：客户端，负责向集群提交作业。")]),v._v(" "),e("p",[v._v("② ResourceManager：集群主进程，仲裁中心，负责集群资源管理和任务调度。")]),v._v(" "),e("p",[v._v("③ Scheduler：资源仲裁模块。")]),v._v(" "),e("p",[v._v("④ ApplicationManager：选定，启动和监管ApplicationMaster。")]),v._v(" "),e("p",[v._v("⑤ NodeManager：集群从进程，管理监视Containers，执行具体任务。")]),v._v(" "),e("p",[v._v("⑥ Container：本机资源集合体，如某Container为4个CPU，8GB内存。")]),v._v(" "),e("p",[v._v("⑦ ApplicationMaster：任务执行和监管中心。")]),v._v(" "),e("p",[e("img",{attrs:{src:a(805),alt:"image-20220404102405923"}})]),v._v(" "),e("p",[e("img",{attrs:{src:a(806),alt:"image-20220404102422109"}})]),v._v(" "),e("p",[v._v("从Yarn架构和Yarn任务执行过程能看出Yarn具有巨大优势：")]),v._v(" "),e("ul",[e("li",[v._v("Scheduler")]),v._v(" "),e("li",[v._v("ApplicationManager")]),v._v(" "),e("li",[v._v("ApplicationMaster")]),v._v(" "),e("li",[v._v("纯粹的资源仲裁中心")]),v._v(" "),e("li",[v._v("只监管ApplicationMaster")]),v._v(" "),e("li",[v._v("负责任务整体执行")])]),v._v(" "),e("p",[v._v("Yarn的设计大大减轻了ResourceManager的资源消耗，并且ApplicationMaster可分布于集群中任意一台机器，设计上更加优美。")]),v._v(" "),e("p",[v._v("除了ResourceManager和NodeManager两个实体外，Yarn还包括WebAppProxyServer和JobHistoryServer两个实体。")]),v._v(" "),e("p",[e("img",{attrs:{src:a(807),alt:"image-20220404102549630"}})]),v._v(" "),e("ul",[e("li",[v._v("JobHistoryServer 管理已完成的Yarn任务\n"),e("ul",[e("li",[v._v("历史任务的日志和执行时的各种统计信息统一由JobTracker管理")]),v._v(" "),e("li",[v._v("Yarn将管理历史任务的功能抽象成一独立实体JobHistoryServer")])])]),v._v(" "),e("li",[v._v("WebAppProxyServer 任务执行时的Web页面代理\n"),e("ul",[e("li",[v._v("通过使用代理，不仅进一步降低了ResourceManager的压力，还能降低Yarn受到的Web攻击")]),v._v(" "),e("li",[v._v("负责监管具体MapReduce任务执行全过程，将从Container那里收集过的任务执行信息汇总并显示到一个Web界面上")])])])]),v._v(" "),e("p",[e("strong",[v._v("编程模板")])]),v._v(" "),e("p",[v._v("ApplicationMaster 是一个可变更的部分，只要实现不同的ApplicationMaster，就可以实现不同的编程模式")]),v._v(" "),e("p",[e("img",{attrs:{src:a(808),alt:"image-20220404102850233"}})]),v._v(" "),e("p",[e("img",{attrs:{src:a(809),alt:"image-20220404102910466"}})]),v._v(" "),e("p",[v._v("一个MapReduce操作分为两个阶段：映射阶段和化简阶段。")]),v._v(" "),e("ul",[e("li",[v._v("映射阶段\n"),e("ul",[e("li",[v._v("MapReduce框架将用户输入的数据分割为M个片断，对应M个Map任务。")])])]),v._v(" "),e("li",[v._v("化简阶段\n"),e("ul",[e("li",[v._v("每一个Reduce操作的输入是一个<K2,list(V2)>片断，Reduce操作调用用户定义的Reduce函数，生成用户需要的键值对<K3,V3>进行输出。")])])])]),v._v(" "),e("p",[e("strong",[v._v("调度策略")])]),v._v(" "),e("p",[v._v("ResourceManager的Scheduler模块支持插拔，通过配置文件，用户可以个性化指定其调度策略")]),v._v(" "),e("p",[e("img",{attrs:{src:a(810),alt:"image-20220404103956020"}})]),v._v(" "),e("p",[e("strong",[v._v("容量调度算法")])]),v._v(" "),e("ul",[e("li",[e("p",[v._v("CapacityScheduler是一种多用户多任务调度策略，它以队列为单位划分任务，以Container为单位分配资源，它也是Hadoop 2.0默认的调度策略，为多个用户共享集群资源提供安全可靠的保障。")])]),v._v(" "),e("li",[e("p",[v._v("通过共建集群的方式，不但可以提高资源利用率，还能在必要时刻使用更多的集群资源，同时，组织机构间共建集群也大大降低了运维成本，")])]),v._v(" "),e("li",[e("p",[v._v("容量调度策略通过队列来划分资源，队列间关系类似于一棵多叉树，队列间一层层继承，根队列称为root队列，Yarn初次启动时默认启动队列为root.default队列。")])]),v._v(" "),e("li",[e("p",[v._v("多级队列")]),v._v(" "),e("ul",[e("li",[v._v("容量调度策略以队列来划分集群资源，不同机构可以在集群里新建不同队列")])])]),v._v(" "),e("li",[e("p",[v._v("容量确定性")]),v._v(" "),e("ul",[e("li",[v._v("规定某队列占用集群资源的上下限，能够确保即使其他队列用到其最高峰时，也能预留充足资源留给此队列")])])]),v._v(" "),e("li",[e("p",[v._v("安全性")]),v._v(" "),e("ul",[e("li",[v._v("每个队列都有相应的访问控制列表ACL文件")])])]),v._v(" "),e("li",[e("p",[v._v("弹性")]),v._v(" "),e("ul",[e("li",[v._v("通过设置队列额外资源使用量，能够让此队列使用超出规定的资源量")])])]),v._v(" "),e("li",[e("p",[v._v("多用户")]),v._v(" "),e("ul",[e("li",[v._v("通过设置不同队列拥有资源的比例，避免某用户或某进程独占集群资源，实现多用户多任务调度")])])]),v._v(" "),e("li",[e("p",[v._v("易操作性")]),v._v(" "),e("ul",[e("li",[v._v("主要包括实时配置和实时更改队列状态")])])]),v._v(" "),e("li",[e("p",[v._v("默认队列")]),v._v(" "),e("ul",[e("li",[v._v("公平调度策略也通过队列来组织和管理任务，并且也支持多级队列，其队列之间为多叉树结构")])])]),v._v(" "),e("li",[e("p",[v._v("队列间权重配置")]),v._v(" "),e("ul",[e("li",[v._v("设置某队列资源权重，权重越大，获得资源的比例越大")])])]),v._v(" "),e("li",[e("p",[v._v("队列内多调度策略")]),v._v(" "),e("ul",[e("li",[v._v("队列内部的调度策略是可配置的，默认为FairSharePolicy策略")])])]),v._v(" "),e("li",[e("p",[v._v("队列下限")]),v._v(" "),e("ul",[e("li",[v._v("为每个队列设置资源下限值，大大提高集群资源利用率")])])]),v._v(" "),e("li",[e("p",[v._v("支持多用户")]),v._v(" "),e("ul",[e("li",[v._v("通过多级队列可以将不同的用户分配到不同的队列里")])])]),v._v(" "),e("li",[e("p",[v._v("访问控制列表ACL")]),v._v(" "),e("ul",[e("li",[v._v("管理员可以设置队列的ACL文件，严格控制用户访问")])])])]),v._v(" "),e("h3",{attrs:{id:"_5-4-4-hadoop-2-0安全机制简介"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_5-4-4-hadoop-2-0安全机制简介"}},[v._v("#")]),v._v(" 5.4.4  Hadoop 2.0安全机制简介")]),v._v(" "),e("p",[e("img",{attrs:{src:a(811),alt:"image-20220404104548076"}})]),v._v(" "),e("p",[v._v("使用Kerberos来实现Hadoop用户认证\nKerberos      鉴定登录用户（服务）是否是其声称的用户（服务）\nHadoop       决定这个用户到底拥有多少权限")]),v._v(" "),e("h2",{attrs:{id:"_5-5-hadoop-2-0访问接口"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_5-5-hadoop-2-0访问接口"}},[v._v("#")]),v._v(" 5.5 Hadoop 2.0访问接口")]),v._v(" "),e("ul",[e("li",[v._v("浏览器接口")])]),v._v(" "),e("table",[e("thead",[e("tr",[e("th"),v._v(" "),e("th",[e("strong",[v._v("Web地址")])]),v._v(" "),e("th",[e("strong",[v._v("配置文件")])]),v._v(" "),e("th",[e("strong",[v._v("配置参数")])])])]),v._v(" "),e("tbody",[e("tr",[e("td",[v._v("HDFS")]),v._v(" "),e("td",[v._v("http://NameNodeHostName:50070")]),v._v(" "),e("td",[v._v("hdfs-site.xml")]),v._v(" "),e("td",[v._v("{dfs.namenode.http-address}")])]),v._v(" "),e("tr",[e("td",[v._v("Yarn")]),v._v(" "),e("td",[v._v("http://ResourceManagerHostName:8088")]),v._v(" "),e("td",[v._v("yarn-site.xml")]),v._v(" "),e("td",[v._v("{  yarn.resourcemanager.webapp.address}")])]),v._v(" "),e("tr",[e("td",[v._v("MapReduce")]),v._v(" "),e("td",[v._v("http://JobHistoryHostName:19888")]),v._v(" "),e("td",[v._v("mapred-site.xml")]),v._v(" "),e("td",[v._v("{mapreduce.jobhistory.webapp.address}")])])])]),v._v(" "),e("p",[v._v("在Hadoop 2.0里，MapReduce是Yarn不可缺少的模块，这里的JobHistory是一个任务独立模块，用来查看历史任务，和MapReduce并行处理算法无关。")]),v._v(" "),e("ul",[e("li",[v._v("命令接口")])]),v._v(" "),e("ol",[e("li",[e("p",[v._v("HDFS   以tar包方式部署时，其执行方式是HADOOP_HOME/bin/hdfs，当以完全模式部署时，使用HDFS用户执行hdfs即可")])]),v._v(" "),e("li",[e("p",[v._v("Yarn   以tar包方式部署时，其执行方式是HADOOP_HOME/bin/yarn，当以完全模式部署时，使用Yarn用户执行yarn即可")]),v._v(" "),e("ol",[e("li",[v._v("每一条命令都包含若干条子命令，Yarn的Shell命令也主要分为用户命令和管理员命令。")])])]),v._v(" "),e("li",[e("p",[v._v("Hadoop    以tar包方式部署时，其执行方式是HADOOP_HOME/bin/Hadoop，当以完全模式部署时，在终端直接执行hadoop")]),v._v(" "),e("ol",[e("li",[v._v("这个脚本既包含HDFS里最常用命令fs（即HDFS里的dfs），又包含Yarn里最常用命令jar，可以说是HDFS和Yarn的结合体。")]),v._v(" "),e("li",[v._v("此外，distcp用mapreduce来实现两个Hadoop集群之间大规模数据复制。")])])]),v._v(" "),e("li",[e("p",[v._v("其他常用命令")]),v._v(" "),e("ol",[e("li",[v._v("sbin/目录下的脚本主要分为两种类型：启停服务脚本和管理服务脚本。\n其中，脚本hadoop-daemon.sh可单独用于启动本机服务，方便本机调试，start/stop类脚本适用于管理整个集群，读者只要在命令行下直接使用这些脚本，它会自动提示使用方法。")])])])])])}),[],!1,null,null,null);_.default=t.exports},794:function(v,_,a){v.exports=a.p+"assets/img/image-20220323103712069.78d4694b.png"},795:function(v,_,a){v.exports=a.p+"assets/img/image-20220323104627420.e48aa054.png"},796:function(v,_,a){v.exports=a.p+"assets/img/image-20220323104856025.d2c8f9de.png"},797:function(v,_,a){v.exports=a.p+"assets/img/image-20220323104825938.5cea8bb8.png"},798:function(v,_,a){v.exports=a.p+"assets/img/image-20220323105729108.4e5aad83.png"},799:function(v,_,a){v.exports=a.p+"assets/img/image-20220323110422292.98f59fec.png"},800:function(v,_,a){v.exports=a.p+"assets/img/image-20220323111007431.7c1306c1.png"},801:function(v,_,a){v.exports=a.p+"assets/img/image-20220404090024554.05b027e6.png"},802:function(v,_,a){v.exports=a.p+"assets/img/image-20220404090545677.48376139.png"},803:function(v,_,a){v.exports=a.p+"assets/img/image-20220404091123149.a2bc5e05.png"},804:function(v,_,a){v.exports=a.p+"assets/img/image-20220404102327980.05d7ed55.png"},805:function(v,_,a){v.exports=a.p+"assets/img/image-20220404102405923.af6d2094.png"},806:function(v,_,a){v.exports=a.p+"assets/img/image-20220404102422109.cc053d59.png"},807:function(v,_,a){v.exports=a.p+"assets/img/image-20220404102549630.8d89e099.png"},808:function(v,_,a){v.exports=a.p+"assets/img/image-20220404102850233.7eb15397.png"},809:function(v,_,a){v.exports=a.p+"assets/img/image-20220404102910466.9d71be82.png"},810:function(v,_,a){v.exports=a.p+"assets/img/image-20220404103956020.1d9c1ef6.png"},811:function(v,_,a){v.exports=a.p+"assets/img/image-20220404104548076.146b51df.png"}}]);